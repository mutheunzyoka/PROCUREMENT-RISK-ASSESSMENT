{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e0d348-ce43-498b-a356-00480234b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTATION OF LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest # we are using it to get data that has high supplier risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d290a7d5-f9aa-42c2-9225-b83022e4b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADING\n",
    "df=pd.read_csv(\"government-procurement-via-gebiz.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a013bd8-5b8d-4cac-9bef-e9544f7fdef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.FEATURE ENGINEERING\n",
    "supplier_counts = df.groupby(['agency','supplier_name']).size().reset_index(name='supplier_count')\n",
    "#we want to count how many times each supplier was awarded a contract by each agency.\n",
    "df=df.merge(supplier_counts,on=['agency','supplier_name'])\n",
    "#merging the original df and supplier_counts so as to add the column supplier_count to df\n",
    "df['supplier_risk']=np.log(df['supplier_count']+1)\n",
    "#new column created 'supplier_risk' to df \n",
    "# np.log is  often used when you have counts that vary a lot (some suppliers might appear once, others hundreds of times).\n",
    "# Applying a logarithm helps to make these numbers more manageable and reduces the impact of very high counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6207ee56-d95a-44f3-8cfe-ced86c18226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Feature Engineering: Amount Anomaly\n",
    "agency_stats =df.groupby('agency')['awarded_amt'].agg(['mean','std']).reset_index()\n",
    "# Calculates mean and standard deviation of awarded amounts per agency\n",
    "\n",
    "df=df.merge(agency_stats,on='agency')\n",
    "# Merges these statistics back into the main DataFrame.\n",
    "\n",
    "df['amount_risk']=(df['awarded_amt']-df['mean'])/df['std']\n",
    "# Computes Z-scores for each tender amount within its agency group.\n",
    "#Measures how many standard deviations an amount is from its agency mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe182bde-7b6e-456f-8932-4383e45ba396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.  Feature Engineering: Status Risk (Conditional)\n",
    "\n",
    "if 'tender_detail_status' in df.columns: #Checks if the status column exists\n",
    "    suspicious_statuses = ['cancelled', 'direct award', 'negotiated']#Defines suspicious status keywords\n",
    "    df['status_risk']=df['tender_detail_status'].str.lower().str.contains('|'.join(suspicious_statuses)).astype(int)\n",
    "    #Converts status text to lowercase and Flags rows containing any suspicious keywords (1=risky, 0=normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29622b2-30df-42f6-92cb-0de55c7164e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Risk Aggregation\n",
    "df['total_risk'] = df['supplier_risk'] + df['amount_risk'].abs()\n",
    "# combines different \"risk\" factors into a single total_risk score for each procurement record.\n",
    "#Sums supplier risk and absolute amount risk(which quantifies how unusually high or low an awarded amount is compared to the agency's average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e3044f9-0f86-46f5-a47f-9178265445a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supplier_risk    0\n",
      "amount_risk      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['supplier_risk', 'amount_risk']].isnull().sum())\n",
    "df= df.dropna(subset=['supplier_risk', 'amount_risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14fddf99-21c1-49dc-8424-bc5689e165cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#6. Anomaly Detection\n",
    "model = IsolationForest(contamination=0.1,random_state=42)\n",
    "# Initializes Isolation Forest model\n",
    "#`contamination=0.1`: Expects 10% of data to be anomalies\n",
    "#`random_state=42`: Ensures reproducibility\n",
    "\n",
    "df['anomaly_score']=model.fit_predict(df[['supplier_risk','amount_risk']])\n",
    "# Fits model to supplier/amount risk features.\n",
    "#Returns `-1` for anomalies, `1` for normal points.\n",
    "\n",
    "df['is_high_risk'] = (df['anomaly_score'] == -1).astype(int)\n",
    "# Converts anomaly scores to binary flags (1=high risk, 0=normal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "566c33d2-fd71-4fb1-a007-e1c536f143a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'risk_assessment.csv'\n"
     ]
    }
   ],
   "source": [
    "#7. Save results\n",
    "df[['tender_no.','agency','supplier_name','awarded_amt','total_risk','is_high_risk']].to_csv(\"risk_assessment.csv\",index=False)\n",
    "print(\"Results saved to 'risk_assessment.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4072b22-8e24-400e-883f-d9aad4f70084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
